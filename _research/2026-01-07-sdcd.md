---
title: "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models"
date: 2026-01-07
categories: [Research, Vision-Language Models]
tags: [Hallucination Mitigation, Contrastive Decoding, LVLM, Visual Bias, arXiv]
excerpt: "Introducing SDCD, a training-free algorithm that mitigates hallucinations by calibrating model predictions against a structure-disrupted view, effectively suppressing texture-driven biases."
---

### Abstract

Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process.

We identify that **visual statistical bias**, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations.

To address this, we introduce a training-free algorithm called **Structure-Disrupted Contrastive Decoding (SDCD)**, which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.

### The "Bag-of-Patches" Phenomenon

Why do LVLMs hallucinate? A key reason lies in how their vision encoders (like CLIP or ViT) process images.

![CLIP Bag-of-Patches Analysis](/assets/images/sdcd_CLIP_BoP.png)
*Figure 1: Analysis of CLIP's attention behavior.*

![ViT Bag-of-Patches Analysis](/assets/images/sdcd_ViT_BoP.png)
*Figure 2: Analysis of ViT's attention behavior.*

As illustrated in Figures 1 and 2, we observe that Vision Encoders often behave like a **"Bag-of-Patches"**. They are highly sensitive to local textures (e.g., fur, patterns) but surprisingly insensitive to the global arrangement of these patches. 

*   **Left (Original):** The model correctly identifies objects in the original image.
*   **Right (Shuffled):** Even when we completely scramble the image patches, destroying all structural information, the model **still activates** strongly for the same object classes solely based on local textures.

This suggests that the model's confidence is often "spurious"â€”it thinks it sees a dog not because it sees the shape of a dog, but because it sees "dog-like texture". This over-reliance on texture is a major source of hallucinations.

### Method Overview: Structure-Disrupted Contrastive Decoding

![SDCD Framework](/assets/images/sdcd_overview.jpg)

To counter this, SDCD introduces a contrastive decoding strategy:

1.  **Original View ($V$):** The model processes the intact image.
2.  **Structure-Disrupted View ($V'$):** We artificially generate a "negative" view by **randomly shuffling the image patches**. This view contains *only* texture information but *no* structural information.
3.  **Contrastive Calibration:** We subtract the logits of the disrupted view from the original view:
    $$ P_{SDCD}(y|x) \propto \text{softmax}( \text{logit}(y|V) - \alpha \cdot \text{logit}(y|V') ) $$

By doing this, we penalize tokens that are confident in *both* views (meaning they are texture-driven) and boost tokens that are confident *only* in the original view (meaning they rely on valid structure).

### Qualitative Results

![Hallucination Mitigation Example](/assets/images/sdcd_llava_gt_yes.jpg)
*Figure 3: SDCD effectively corrects hallucinations.*

In Figure 3, we see SDCD in action. The standard model (LLaVA) might hallucinate objects based on texture cues. However, by applying SDCD, the model suppresses these false positives and focuses on objects that are structurally present in the scene.

*(Note: We also analyzed failure cases where the model might miss small objects if the structure disruption is too aggressive, as seen in `sdcd_llava_gt_no.jpg`, but overall, the precision is significantly improved.)*

### Key Contributions
*   **Identification of Visual Bias:** Pinpointed "visual statistical bias" caused by the Bag-of-Patches nature of vision encoders as a key source of hallucinations.
*   **Method (SDCD):** Proposed a novel contrastive decoding strategy that uses a structure-disrupted (shuffled) image view as a negative constraint to penalize texture-only reliance.
*   **Training-Free:** The method requires no retraining or fine-tuning of the model.
*   **Performance:** Demonstrated significant reduction in object hallucinations and improved multimodal reasoning capabilities.

### Publication Details
**Authors:** **Yuxuan Xia**, et al.
**Venue:** arXiv:2601.03500 [cs.CV]
**Link:** [arXiv:2601.03500](https://arxiv.org/abs/2601.03500v1)
