---
title: "SDCD: Structure-Disrupted Contrastive Decoding for Mitigating Hallucinations in Large Vision-Language Models"
date: 2026-01-07
categories: [Research, Vision-Language Models]
tags: [Hallucination Mitigation, Contrastive Decoding, LVLM, Visual Bias, arXiv]
excerpt: "Introducing SDCD, a training-free algorithm that mitigates hallucinations by calibrating model predictions against a structure-disrupted view, effectively suppressing texture-driven biases."
---

### Abstract

Large Vision-Language Models (LVLMs) demonstrate significant progress in multimodal understanding and reasoning, yet object hallucination remains a critical challenge. While existing research focuses on mitigating language priors or high-level statistical biases, they often overlook the internal complexities of the visual encoding process.

We identify that **visual statistical bias**, arising from the inherent Bag-of-Patches behavior of Vision Encoders under weak structural supervision, acts as a contributing factor of object hallucinations. Under this bias, models prioritize local texture features within individual patches over holistic geometric structures. This tendency may induce spurious visual confidence and result in hallucinations.

To address this, we introduce a training-free algorithm called **Structure-Disrupted Contrastive Decoding (SDCD)**, which performs contrastive calibration of the output distribution by introducing a shuffled structure-disrupted view. By penalizing tokens that maintain high confidence under this structure-less view, SDCD effectively suppresses the texture-driven bias. Experimental results demonstrate that SDCD significantly mitigates hallucinations across multiple benchmarks and enhances the overall multimodal capabilities of LVLMs.

### The "Bag-of-Patches" Phenomenon

Why do LVLMs hallucinate? A key reason lies in how their vision encoders (like CLIP or ViT) process images.

![CLIP Bag-of-Patches Analysis](/assets/images/sdcd_CLIP_BoP.png)
*Figure 1: Analysis of CLIP's attention behavior.*

![ViT Bag-of-Patches Analysis](/assets/images/sdcd_ViT_BoP.png)
*Figure 2: Analysis of ViT's attention behavior.*

As illustrated in Figures 1 and 2, we observe that Vision Encoders often behave like a **"Bag-of-Patches"**. They are highly sensitive to local textures (e.g., fur, patterns) but surprisingly insensitive to the global arrangement of these patches.

Surprisingly, **even when the input image is completely shuffled**, destroying all global structural information, the performance metrics remain largely unchanged. Specifically, the classification accuracy of **ViT** and the retrieval recall of **CLIP** on shuffled images are comparable to those on original images.

This finding strongly suggests that these models heavily rely on **local-patch texture information** rather than holistic geometric understanding. This over-reliance on texture is a major source of hallucinations, as the model may confidently detect an object solely based on texture cues, even when the object's structure is absent or distorted.

### Structure Sensitivity Divergence in LVLMs

We further investigate how this "Bag-of-Patches" behavior impacts the decoding process of LVLMs. By monitoring the logit dynamics of "Yes" (object present) and "No" (object absent) tokens under both the original view ($V$) and the structure-disrupted view ($V'$), we observe a significant divergence in how the model responds to real versus hallucinated objects.

<div style="display: flex; gap: 20px; margin-bottom: 20px;">
  <div style="flex: 1; text-align: center;">
    <img src="/assets/images/sdcd_llava_gt_yes.jpg" alt="Structure Sensitivity for Real Objects" style="width: 100%;">
    <p><em>(a) GT = Yes (Real Objects)</em></p>
  </div>
  <div style="flex: 1; text-align: center;">
    <img src="/assets/images/sdcd_llava_gt_no.jpg" alt="Structure Sensitivity for Hallucinations" style="width: 100%;">
    <p><em>(b) GT = No (Hallucinations)</em></p>
  </div>
</div>

*   **For Real Objects (a):** When we disrupt the image structure ($V'$), the model's confidence in the correct answer ("Yes") drops sharply. This indicates that recognizing real objects relies heavily on **structural consistency** across patches.
*   **For Hallucinated Objects (b):** Conversely, structural disruption often leads to an **increase** in confidence for the incorrect "Yes" token. This "Texture Unleashed" phenomenon suggests that hallucinations are primarily driven by local texture cues, which become even more dominant when global structure is removed.

This asymmetric sensitivity—where real objects are penalized by structural loss while hallucinations are enhanced—provides the core motivation for SDCD. We can use the structure-disrupted view as a negative control to suppress texture-induced hallucinations.

### Method Overview: Structure-Disrupted Contrastive Decoding

![SDCD Framework](/assets/images/sdcd_overview.jpg)

To counter this, SDCD introduces a contrastive decoding strategy:

1.  **Original View ($V$):** The model processes the intact image.
2.  **Structure-Disrupted View ($V'$):** We artificially generate a "negative" view by **randomly shuffling the image patches**. This view contains *only* texture information but *no* structural information.
3.  **Contrastive Calibration:** We subtract the logits of the disrupted view from the original view:
    $$ P_{SDCD}(y|x) \propto \text{softmax}( \text{logit}(y|V) - \alpha \cdot \text{logit}(y|V') ) $$

By doing this, we penalize tokens that are confident in *both* views (meaning they are texture-driven) and boost tokens that are confident *only* in the original view (meaning they rely on valid structure).

### Qualitative Results

In Figure 3, we see SDCD in action. The standard model (LLaVA) might hallucinate objects based on texture cues. However, by applying SDCD, the model suppresses these false positives and focuses on objects that are structurally present in the scene.

*(Note: We also analyzed failure cases where the model might miss small objects if the structure disruption is too aggressive, but overall, the precision is significantly improved.)*

### Key Contributions
*   **Identification of Visual Bias:** Pinpointed "visual statistical bias" caused by the Bag-of-Patches nature of vision encoders as a key source of hallucinations.
*   **Method (SDCD):** Proposed a novel contrastive decoding strategy that uses a structure-disrupted (shuffled) image view as a negative constraint to penalize texture-only reliance.
*   **Training-Free:** The method requires no retraining or fine-tuning of the model.
*   **Performance:** Demonstrated significant reduction in object hallucinations and improved multimodal reasoning capabilities.

### Publication Details
**Authors:** **Yuxuan Xia**, et al.
**Venue:** arXiv:2601.03500 [cs.CV]
**Link:** [arXiv:2601.03500](https://arxiv.org/abs/2601.03500v1)
